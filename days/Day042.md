Day042 — Twitter NDJSON → RAG素体：壊れにくい“中継点”づくり

🎯 本日のテーマ

今日はなにを操りたくなった？
Twitterアーカイブ（NDJSON）を、RAGにそのまま食わせやすいJSONLチャンクへ正規化して、前処理の型を固める。

きっかけはどんな出来事・気づきやった？
「文書をDB化する処理」を学ぶ実験として、まずは壊れにくい中間フォーマットを用意したかった。

それは自分にとってどんな願い／意味？
“意味を盛る”より流れ（脈絡）を作る。後段の埋め込み／検索を再現可能に回せる足場を残す。


🧠 背景・思想

JSONL＝中立な中継点。埋め込み器やベクトルDB（FAISS/Qdrant/Elasticsearch…）へ直送しやすい。

メタ保持（created_at/lang/is_reply…）は後段のメタフィルタに効く。

NotebookLM向け等の“読み物”は**別パス（Markdown化）**で分ける。役割で形式を分離するのが安定や。


⚙️ 実装と試行

入力：tweets_mamo96358.ndjson（1行=1ツイート）

変換：1ツイート→1チャンクJSONL（最小スキーマ）

出力：

本体：twitter_chunks.jsonl

取り込みログ：ingest_log.jsonl

集計レポート：report_twitter_ingest.md

スクリプト：convert_twitter_ndjson_to_rag.py


結果（レポート抜粋）：総レコード 643／テキストあり 643／エラー 0 → 暫定合格（“30件以上”基準クリア）

今回スキーマ要点：

text は text_expanded→text の優先で抽出

content_sha1 で差分検出・重複排除（インクリメンタル用）

reply_to_status_id / quoted_status_id を保持（後段でスレッド再結合可）



📊 操作フェーズチェック

① 入力の据え方（NDJSONの正規化）

② 出力の形（JSONLチャンク＋ログ＋レポート）

⑤ トリガー設計（再実行・差分更新の前提づくり）

⑥ 選択と接続（RAGパイプラインの接続点を明確化）

⑪ 再帰的な演算（インクリメンタル取り込み）


🔁 洞察と考察

中継点が堅いと、後段が自由になる。 形式の“役割分離”で壊れにくさが上がる。

ログは機能。 成功・失敗・件数が行単位で残るだけで、再実行の怖さが消える。

IDとハッシュは命綱。 content_sha1 があれば増分再埋め込みが現実解になる。

問い直し：Precision@k で「取りたいチャンクが取れているか」を、次フェーズで定量確認する。


🪶 雑記・気づき

意味づけは後からでも盛れる。まずは流れを詰める方が、しんどい日にでも前に進む。


🙏 感謝・引用

NDJSON/JSONLのエコシステムとOSSに感謝。最小の道具で最短の成果が出せたやで。


🛠 次の挑戦メモ

[ ] 埋め込み→インデックスの最小通電（例：LlamaIndex + FAISS）

[ ] 評価セット作成（代表クエリ10–20本＋正解チャンクID）

[ ] 文脈拡張：ヒットの前後3–5件バンドル提示の実装

[ ] ハイブリッド検索（ベクトル＋BM25）をスイッチ可能に

[ ] NotebookLM向けに月次Markdownを別生成（俯瞰・学習用）


📝 タイトル

NDJSON→JSONL：RAGの“素体”を整える日

🏷 タグ

#RAG #NDJSON #JSONL #TwitterArchive #正規化 #インクリメンタル #ベクトル検索 #FAISS #LlamaIndex #評価設計

