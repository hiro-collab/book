# Day011 - 話せるプロジェクションマッピングをつくる

## 🎯 願いとテーマ

きっかけとなる願いは、話のできるプロジェクションマッピングを夏のお盆のコミケイベントまでに作成し、会場外でパフォーマンスをしたいと考えたから。  
映像の中に自身と相互作用（会話）できる存在がいて、それが現実空間にプロジェクター投影され存在する。デジタルな存在が現実空間に存在する、というシステムを多くの人に見せたかった。プロジェクターによる空間型拡張現実のデモ。

これにより、従来のスマホや眼鏡をかけることによる「見る人の能動的な視聴」だけでなく、見せる人の能動的な働きにより人の目を奪うことができる。

それにより、拡張現実は一方通行ではなく、人と人がつながった対話形式になる。現実空間にあるから逃げることもできず、強制力が増す。より力のある、現実時間のある拡張現実が実現する。

## ❓ Day011 質問ベースの記録

### 1. なぜこのシステムを作りたいのか？

- **問い：なぜ「話せるプロジェクションマッピング」を作ろうと思ったのか？**  
  → 夏のお盆コミケイベントで、会場外にて注目を集めるパフォーマンスをしたい。  
  映像の中に「自分に反応する存在」がいて、現実空間に存在することで「一方通行じゃない対話」を実現したい。

### 2. なにが従来の体験と違うのか？

- **問い：スマホやVRと何が違うのか？**  
  → 従来は「見る人の能動性」が前提だったけど、今回は「見せる人の能動性」により、人の注意を奪うことができる。  
  “自分が操作して見る”ではなく、“現実世界に干渉される”体験ができる。

### 3. このシステムはどんな力を持つのか？

- **問い：このデモが実現すると、どんな影響がある？**  
  → 現実空間に現れるデジタル存在が「逃げられない対話」を生む。  
  より「力のある」拡張現実（Hyper Reality）が、人を巻き込む形で成立する。

### 4. 今日の作業は何だったのか？

- DifyのOpenAIキーを作成し、ローカル上で立ち上げ確認。
- ワークフローを作成して、Webhookで録音をトリガーする構成を試した。
- Whisperの無料/有料の精度や実用性に悩み中。

---

## 🎯 テーマの背景と思い

### ❓ このテーマの背景にある、自分の身体感覚・過去の経験は？

私の祖母は全盲で、母の世話を十分に行うことができなかった。  
母には父親もおらず、家族としての基盤が不足していた。  
私自身も脳に障害を抱えており、家族を十分に支えることができなくなった。

それでも、人としてまっとうに生きたい。  
そして、人的資源として社会や経済に貢献したい。  
── 祖母も、もし代わりの「目玉」を得られていたなら、馬車馬のように働くことができたはずだ。

この思いが、プロジェクションマッピングの中に「対話できる存在」をつくり出すという今回のテーマに繋がっている。

### ❓ 「サイバー」や「可視化」は、自分にとってどんな意味？

サイバーとは、操ること。  
可視化とは、それを操るためのメディアを実体化すること。  

目に見えず、操作できなかった「能力」「思考」「存在」を、  
可視化して現実に引き出し、操れるようにする。  
そのための技術、それが私にとっての「サイバー」であり「可視化」。

### ❓ 今日のテーマは、自分の障害や制限とどう関係しているか？

体に不自由があっても、代わりの者──  
それがたとえ人間でなくても、デジタル空間を介した存在が、  
家族や友人として干渉し、自分の代わりに社会の役目を果たすことができる。

「できなかったこと」をAIやプログラムが担い、  
人 → モデル → AI → 機能提供、という形で  
社会の中で「機能を果たす」ことができる仕組みをつくる。

それは、個人の限界を超えて、もう一度「つながる」方法でもある。

---

## ⚙️ 3. 実装と試行

### 💻 どんなツールや技術を使った？

- Dify（AIチャット＋ワークフロー構築）
- FastAPI（Webhookトリガー → 音声録音 → Whisper連携のサーバー）
- Python + sounddevice + scipy + tempfile
- OpenAI Whisper API
- Windows + Logicool C920（USBマイク内蔵カメラ）

### 🤔 なぜそれを選んだん？

- DifyはノーコードでChatフローが組めるし、Webhookで外部スクリプト呼び出しができるから。
- FastAPIは軽量でWebhook受け取りと非同期処理に強い。
- Whisperは日本語音声認識で無料枠があり、精度も実用レベル。
- 手元のWindows PCとLogicoolカメラで構成でき、環境構築がすぐできた。

### 🧠 工夫・つまずき・発見は？

- `docker-compose.yml` がルートに無くて、 `docker/docker-compose.yaml` をコピーして起動。
- `.env` 設定が多数あり、最小構成でまず立ち上げ確認。
- DifyのWorkflow構築では WebhookノードのJSON整形と、トリガー入力の構文が少し分かりづらかった。

---

## 🔍 4. 操作フェーズチェック

今日は以下のフェーズに関係：

① 入力の捉え方  
→ 音声を入力手段として扱う試み。Difyでテキストトリガーから音声処理へ橋渡し。

④ 見られ方の操作（出力の形）  
→ Whisperにより生成された文字列が、Chatに自然な返答として表示される仕組み。

⑥ 選択と接続  
→ Difyのワークフロー構成（Trigger→Webhook→Response）と、FastAPIのWebhook構成。

⑧ 相互作用  
→ 人が「録音して」と打つことで、録音・認識・返答が発生する。人とAIの双方向性の試み。

⑪ 再帰演算  
→ 既存ライブラリやAPI（Whisper）を使って、入力と出力をループさせる処理フロー。
